{
    "model_name_or_path": "google/gemma-2b-it",
    "predict_with_generate": true,
    "per_device_train_batch_size": 4,
    "per_device_eval_batch_size": 4,
    "gradient_accumulation_steps": 8,
    "cache_dir": "/path/to/.cache",
    "max_input_length": 1024,
    "max_output_length": 128,
    "optimizer_name": "IVON",
    "weight_decay": 1e-06,
    "warmup_steps": 512,
    "min_lr": 0.0,
    "beta1": 0.9,
    "beta2": 0.99999,
    "hess_init": 0.0003,
    "ess": 10000000.0,
    "max_grad_norm": 1.0,
    "learning_rate": 0.03,
    "clip_radius": 0.001,
    "evaluation_strategy": "epoch",
    "save_strategy": "epoch",
    "use_peft": true,
    "manual_seed": 1,
    "use_auth_token": "TODO",
    "prompt_prefix": "Translate from English to German: ",
    "method": "causal_seq2seq",
    "output_dir": "example-models",
    "num_train_epochs": 1,
    "logging_strategy": "steps",
    "logging_steps": 128,
    "overwrite_output_dir": true,
    "dataset_name": "/path/to/iclr2025-mbr-uncertainty/huggingface/code/mbr/datasets/iwslt17.py",
    "dataset_config_name": "seq2seq",
    "dataset_train_split": "train",
    "dataset_val_split": "test[:2%]",
    "dataset_test_split": "test[:2%]"
}